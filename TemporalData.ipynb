{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the Data\n",
    "file_path = \"Dataset/diabetic_data_training.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal dataset saved as temporal_dataset.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Basic Data Inspection\n",
    "#print(df.info())\n",
    "#print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle Missing Values\n",
    "# Replace '?' with NaN for easier processing\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Impute missing values for numerical columns\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[num_cols] = imputer.fit_transform(df[num_cols])\n",
    "\n",
    "# Fill categorical missing values with the mode\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Encode Categorical Variables\n",
    "# Encode categorical columns using one-hot encoding and LabelEncoder\n",
    "encode_cols = ['gender', 'race', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n",
    "df = pd.get_dummies(df, columns=encode_cols)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['readmitted'] = label_encoder.fit_transform(df['readmitted'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal data saved as temporal_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Feature Engineering on Temporal Data\n",
    "# Sort by patient and encounter\n",
    "df.sort_values(by=['patient_nbr', 'encounter_id'], inplace=True)\n",
    "\n",
    "# Aggregate features by patient\n",
    "agg_features = df.groupby('patient_nbr').agg({\n",
    "    'time_in_hospital': ['sum', 'mean', 'max'],\n",
    "    'num_lab_procedures': ['sum', 'mean'],\n",
    "    'num_medications': ['sum', 'mean'],\n",
    "    'number_outpatient': ['sum'],\n",
    "    'number_emergency': ['sum'],\n",
    "    'number_inpatient': ['sum']\n",
    "}).reset_index()\n",
    "agg_features.columns = ['_'.join(col) for col in agg_features.columns]\n",
    "\n",
    "# Create lag features\n",
    "for col in ['time_in_hospital', 'num_lab_procedures', 'num_medications']:\n",
    "    df[f'prev_{col}'] = df.groupby('patient_nbr')[col].shift(1).fillna(0)\n",
    "\n",
    "\n",
    "# Create rolling features\n",
    "#df['rolling_lab_procedures'] = df.groupby('patient_nbr')['num_lab_procedures'].rolling(3).mean().reset_index(0, drop=True)\n",
    "\n",
    "# Create rolling features for multiple variables\n",
    "rolling_features = ['time_in_hospital', 'num_lab_procedures', 'num_medications', \n",
    "                    'number_outpatient', 'number_emergency']\n",
    "for col in rolling_features:\n",
    "    df[f'rolling_mean_{col}'] = df.groupby('patient_nbr')[col].rolling(3).mean().reset_index(0, drop=True)\n",
    "    df[f'rolling_sum_{col}'] = df.groupby('patient_nbr')[col].rolling(3).sum().reset_index(0, drop=True)\n",
    "    df[f'rolling_std_{col}'] = df.groupby('patient_nbr')[col].rolling(3).std().reset_index(0, drop=True)\n",
    "\n",
    "# Combine aggregated features back to original DataFrame\n",
    "df = pd.merge(df, agg_features, left_on='patient_nbr', right_on='patient_nbr_')\n",
    "\n",
    "# Drop redundant columns\n",
    "df.drop(columns=['patient_nbr_'], inplace=True)\n",
    "\n",
    "# Generate Timestep for Each Patient (Visit Number)\n",
    "df['timestep'] = df.groupby('patient_nbr').cumcount() + 1\n",
    "\n",
    "# Extract Temporal Features (Cumulative Features)\n",
    "df['cumulative_time_in_hospital'] = df.groupby('patient_nbr')['time_in_hospital'].cumsum()\n",
    "df['cumulative_lab_procedures'] = df.groupby('patient_nbr')['num_lab_procedures'].cumsum()\n",
    "df['cumulative_medications'] = df.groupby('patient_nbr')['num_medications'].cumsum()\n",
    "\n",
    "# Select Relevant Columns (Keep Timestep)\n",
    "temporal_cols = [col for col in df.columns if col not in ['encounter_id']]\n",
    "temporal_data = df[temporal_cols]\n",
    "\n",
    "# Save the temporal data to CSV for external use\n",
    "temporal_data.to_csv(r'C:\\Users\\vidur\\Desktop\\Temp\\temporal_dataset(2).csv', index=False)\n",
    "\n",
    "print(\"Temporal data saved as temporal_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Prepare Data for Modeling\n",
    "# Drop unnecessary columns\n",
    "X = df.drop(columns=['readmitted', 'encounter_id', 'patient_nbr'])\n",
    "y = df['readmitted']\n",
    "\n",
    "# Train-Test Split (Group by patient to avoid data leakage)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Tuned Model Accuracy: 0.7306474505950431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.03      0.06      2106\n",
      "           1       0.66      0.63      0.64      6329\n",
      "           2       0.77      0.94      0.85      9883\n",
      "\n",
      "    accuracy                           0.73     18318\n",
      "   macro avg       0.66      0.54      0.52     18318\n",
      "weighted avg       0.71      0.73      0.69     18318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Step 7: Train a Random Forest Model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Convert DataFrame to numerical format\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill any remaining NaN values after conversion\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "print(\"Top Features:\")\n",
    "print(feature_importances.head(10))\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
